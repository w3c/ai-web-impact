<!DOCTYPE html><html lang="en-us"><head>
<meta charset="utf-8">
<meta name="generator" content="ReSpec 35.0.2">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<style>
dfn{cursor:pointer}
.dfn-panel{position:absolute;z-index:35;min-width:300px;max-width:500px;padding:.5em .75em;margin-top:.6em;font-family:"Helvetica Neue",sans-serif;font-size:small;background:#fff;background:var(--indextable-hover-bg,#fff);color:#000;color:var(--text,#000);box-shadow:0 1em 3em -.4em rgba(0,0,0,.3),0 0 1px 1px rgba(0,0,0,.05);box-shadow:0 1em 3em -.4em var(--tocsidebar-shadow,rgba(0,0,0,.3)),0 0 1px 1px var(--tocsidebar-shadow,rgba(0,0,0,.05));border-radius:2px}
.dfn-panel:not(.docked)>.caret{position:absolute;top:-9px}
.dfn-panel:not(.docked)>.caret::after,.dfn-panel:not(.docked)>.caret::before{content:"";position:absolute;border:10px solid transparent;border-top:0;border-bottom:10px solid #fff;border-bottom-color:var(--indextable-hover-bg,#fff);top:0}
.dfn-panel:not(.docked)>.caret::before{border-bottom:9px solid #a2a9b1;border-bottom-color:var(--indextable-hover-bg,#a2a9b1)}
.dfn-panel *{margin:0}
.dfn-panel b{display:block;color:#000;color:var(--text,#000);margin-top:.25em}
.dfn-panel ul a[href]{color:#333;color:var(--text,#333)}
.dfn-panel>div{display:flex}
.dfn-panel a.self-link{font-weight:700;margin-right:auto}
.dfn-panel .marker{padding:.1em;margin-left:.5em;border-radius:.2em;text-align:center;white-space:nowrap;font-size:90%;color:#040b1c}
.dfn-panel .marker.dfn-exported{background:#d1edfd;box-shadow:0 0 0 .125em #1ca5f940}
.dfn-panel .marker.idl-block{background:#8ccbf2;box-shadow:0 0 0 .125em #0670b161}
.dfn-panel a:not(:hover){text-decoration:none!important;border-bottom:none!important}
.dfn-panel a[href]:hover{border-bottom-width:1px}
.dfn-panel ul{padding:0}
.dfn-panel li{margin-left:1em}
.dfn-panel.docked{position:fixed;left:.5em;top:unset;bottom:2em;margin:0 auto;max-width:calc(100vw - .75em * 2 - .5em - .2em * 2);max-height:30vh;overflow:auto}
</style>
  
<title>AI &amp; the Web: Understanding and managing the impact of Machine Learning models on the Web</title>
  
  
<meta name="color-scheme" content="light dark">
  
<style>

    a[href].internalDFN {
	border-bottom-style: dotted;
    }
  
</style>
  
<script>var respecConfig = {
    status: "UD",
    editors: [ {name: "Dominique Hazael-Massieux", email: "dom@w3.org"}],
    latestVersion: "https://www.w3.org/reports/ai-web-impact/",
  otherLinks: [
    {
      "key": "Translations",
      data: [
	{
	  value: "简体中文 (Simplified Chinese)",
	  href: "index-zh.html"
	}
      ]
    }
  ],
    localBiblio: {
	"ISO/IEC-22989": {
	    href: "https://www.iso.org/standard/74296.html",
	    title: "Artificial intelligence concepts and terminology",
            "status": "Published",
            "publisher": "ISO/IEC",
            "isoNumber": "ISO 22989:2022",
            "date": "July 2022"
	},
	"C2PA-AI": {
	    href: "https://c2pa.org/specifications/specifications/1.3/ai-ml/ai_ml.html",
	    title: "Guidance for Artificial Intelligence and Machine Learning",
	    publisher: "C2PA"
	},
	"IPTC-DST": {
	    title: "Digital Source Type vocabulary",
	    href: "https://cv.iptc.org/newscodes/digitalsourcetype/",
	    publisher: "IPTC"
	},
	"UNESCO-AI": {
	    "href": "https://unesdoc.unesco.org/ark:/48223/pf0000380455",
	    "title": "Recommendation on the Ethics of Artificial Intelligence",
	    "publisher": "UNESCO",
	    "date": "2021"
	},
	"WAI-AI": {
	    title: "Artificial Intelligence (AI) and Accessibility Research Symposium 2023",
	    href: "https://www.w3.org/WAI/research/ai2023/",
	    publisher: "W3C Web Accessibility Initiative",
	    date: "Jan 2023"
	},
	"MODEL-CARDS": {
	    title: "Model Cards for Model Reporting",
	    href: "https://arxiv.org/pdf/1810.03993.pdf",
	    authors: ["M. Mitchell", "S. Wu", "A. Zaldivar", "P. Barnes", "L. Vasserman", "B. Hutchinson", "E. Spitzer", "I. Deborah Raji", "T. Gebru"],
	    date: "14 Juan 2019"
	},
	"W3C-ML-WS": {
	    "title": "W3C Workshop Report on Web and Machine Learning",
	    href: "https://www.w3.org/2020/06/machine-learning-workshop/report.html",
	    publisher: "W3C",
	    date: "October 2020"
	},
	"DIGITAL-CREDENTIALS": {
	    href: "https://wicg.github.io/digital-identities/",
	    title: "Digital Credentials",
	    publisher: "WICG",
	    date: "March 2024"
	},
	"TDMRep": {
	    href: "https://www.w3.org/community/reports/tdmrep/CG-FINAL-tdmrep-20240202/",
	    title: "Final Community Group Report",
	    date: "February 2024",
	    publisher: "Text and Data Mining Reservation Protocol Community Group"
	},
      "TRUST.TXT": {
	href: "https://journallist.net/reference-document-for-trust-txt-specifications",
	title: "Specification for trust.txt file and underlying system",
	date: "May 2020",
	publisher: "JournalList.net"
      }
    },
    github: "https://github.com/w3c/ai-web-impact",
    edDraftURI: null,
    postProcess: [
	function() {
	    // remove first (auto-generated) paragraph of SOTD
	    document.getElementById("sotd").querySelector("p").remove();
	}
    ]
}</script>

  
<style id="respec-mainstyle">
@keyframes pop{
0%{transform:scale(1,1)}
25%{transform:scale(1.25,1.25);opacity:.75}
100%{transform:scale(1,1)}
}
a.internalDFN{color:inherit;border-bottom:1px solid #99c;text-decoration:none}
a.externalDFN{color:inherit;border-bottom:1px dotted #ccc;text-decoration:none}
a.bibref{text-decoration:none}
.respec-offending-element:target{animation:pop .25s ease-in-out 0s 1}
.respec-offending-element,a[href].respec-offending-element{text-decoration:red wavy underline}
@supports not (text-decoration:red wavy underline){
.respec-offending-element:not(pre){display:inline-block}
.respec-offending-element{background:url(data:image/gif;base64,R0lGODdhBAADAPEAANv///8AAP///wAAACwAAAAABAADAEACBZQjmIAFADs=) bottom repeat-x}
}
#references :target{background:#eaf3ff;animation:pop .4s ease-in-out 0s 1}
cite .bibref{font-style:normal}
a[href].orcid{padding-left:4px;padding-right:4px}
a[href].orcid>svg{margin-bottom:-2px}
ol.tof,ul.tof{list-style:none outside none}
.caption{margin-top:.5em;font-style:italic}
#issue-summary>ul{column-count:2}
#issue-summary li{list-style:none;display:inline-block}
details.respec-tests-details{margin-left:1em;display:inline-block;vertical-align:top}
details.respec-tests-details>*{padding-right:2em}
details.respec-tests-details[open]{z-index:999999;position:absolute;border:thin solid #cad3e2;border-radius:.3em;background-color:#fff;padding-bottom:.5em}
details.respec-tests-details[open]>summary{border-bottom:thin solid #cad3e2;padding-left:1em;margin-bottom:1em;line-height:2em}
details.respec-tests-details>ul{width:100%;margin-top:-.3em}
details.respec-tests-details>li{padding-left:1em}
.self-link:hover{opacity:1;text-decoration:none;background-color:transparent}
aside.example .marker>a.self-link{color:inherit}
.header-wrapper{display:flex;align-items:baseline}
:is(h2,h3,h4,h5,h6):not(#toc>h2,#abstract>h2,#sotd>h2,.head>h2){position:relative;left:-.5em}
:is(h2,h3,h4,h5,h6):not(#toch2)+a.self-link{color:inherit;order:-1;position:relative;left:-1.1em;font-size:1rem;opacity:.5}
:is(h2,h3,h4,h5,h6)+a.self-link::before{content:"§";text-decoration:none;color:var(--heading-text)}
:is(h2,h3)+a.self-link{top:-.2em}
:is(h4,h5,h6)+a.self-link::before{color:#000}
@media (max-width:767px){
dd{margin-left:0}
}
@media print{
.removeOnSave{display:none}
}
</style>

<meta name="description" content="This document proposes an analysis of the systemic impact of AI systems, and in particular ones based on Machine Learning models, on the Web, and the role that Web standardization may play in managing that impact.">
<style>
var{position:relative;cursor:pointer}
var[data-type]::after,var[data-type]::before{position:absolute;left:50%;top:-6px;opacity:0;transition:opacity .4s;pointer-events:none}
var[data-type]::before{content:"";transform:translateX(-50%);border-width:4px 6px 0 6px;border-style:solid;border-color:transparent;border-top-color:#222}
var[data-type]::after{content:attr(data-type);transform:translateX(-50%) translateY(-100%);background:#222;text-align:center;font-family:"Dank Mono","Fira Code",monospace;font-style:normal;padding:6px;border-radius:3px;color:#daca88;text-indent:0;font-weight:400}
var[data-type]:hover::after,var[data-type]:hover::before{opacity:1}
</style>
<script id="initialUserConfig" type="application/json">{
  "status": "UD",
  "editors": [
    {
      "name": "Dominique Hazael-Massieux",
      "email": "dom@w3.org"
    }
  ],
  "latestVersion": "https://www.w3.org/reports/ai-web-impact/",
  "otherLinks": [
    {
      "key": "Translations",
      "data": [
        {
          "value": "简体中文 (Simplified Chinese)",
          "href": "index-zh.html"
        }
      ]
    }
  ],
  "localBiblio": {
    "ISO/IEC-22989": {
      "href": "https://www.iso.org/standard/74296.html",
      "title": "Artificial intelligence concepts and terminology",
      "status": "Published",
      "publisher": "ISO/IEC",
      "isoNumber": "ISO 22989:2022",
      "date": "July 2022",
      "id": "iso/iec-22989"
    },
    "C2PA-AI": {
      "href": "https://c2pa.org/specifications/specifications/1.3/ai-ml/ai_ml.html",
      "title": "Guidance for Artificial Intelligence and Machine Learning",
      "publisher": "C2PA",
      "id": "c2pa-ai"
    },
    "IPTC-DST": {
      "title": "Digital Source Type vocabulary",
      "href": "https://cv.iptc.org/newscodes/digitalsourcetype/",
      "publisher": "IPTC",
      "id": "iptc-dst"
    },
    "UNESCO-AI": {
      "href": "https://unesdoc.unesco.org/ark:/48223/pf0000380455",
      "title": "Recommendation on the Ethics of Artificial Intelligence",
      "publisher": "UNESCO",
      "date": "2021",
      "id": "unesco-ai"
    },
    "WAI-AI": {
      "title": "Artificial Intelligence (AI) and Accessibility Research Symposium 2023",
      "href": "https://www.w3.org/WAI/research/ai2023/",
      "publisher": "W3C Web Accessibility Initiative",
      "date": "Jan 2023",
      "id": "wai-ai"
    },
    "MODEL-CARDS": {
      "title": "Model Cards for Model Reporting",
      "href": "https://arxiv.org/pdf/1810.03993.pdf",
      "authors": [
        "M. Mitchell",
        "S. Wu",
        "A. Zaldivar",
        "P. Barnes",
        "L. Vasserman",
        "B. Hutchinson",
        "E. Spitzer",
        "I. Deborah Raji",
        "T. Gebru"
      ],
      "date": "14 Juan 2019",
      "id": "model-cards"
    },
    "W3C-ML-WS": {
      "title": "W3C Workshop Report on Web and Machine Learning",
      "href": "https://www.w3.org/2020/06/machine-learning-workshop/report.html",
      "publisher": "W3C",
      "date": "October 2020",
      "id": "w3c-ml-ws"
    },
    "DIGITAL-CREDENTIALS": {
      "href": "https://wicg.github.io/digital-identities/",
      "title": "Digital Credentials",
      "publisher": "WICG",
      "date": "March 2024",
      "id": "digital-credentials"
    },
    "TDMRep": {
      "href": "https://www.w3.org/community/reports/tdmrep/CG-FINAL-tdmrep-20240202/",
      "title": "Final Community Group Report",
      "date": "February 2024",
      "publisher": "Text and Data Mining Reservation Protocol Community Group",
      "id": "tdmrep"
    },
    "TRUST.TXT": {
      "href": "https://journallist.net/reference-document-for-trust-txt-specifications",
      "title": "Specification for trust.txt file and underlying system",
      "date": "May 2020",
      "publisher": "JournalList.net",
      "id": "trust.txt"
    }
  },
  "github": "https://github.com/w3c/ai-web-impact",
  "edDraftURI": null,
  "postProcess": [
    null
  ],
  "publishISODate": "2024-05-13T00:00:00.000Z",
  "generatedSubtitle": "13 May 2024"
}</script>
<link rel="stylesheet" href="https://www.w3.org/StyleSheets/TR/2021/base.css">
<link rel="stylesheet" media="(prefers-color-scheme: dark)" href="https://www.w3.org/StyleSheets/TR/2021/dark.css"></head>

<body class="h-entry informative"><div class="head">
    
    <h1 id="title" class="title">AI &amp; the Web: Understanding and managing the impact of Machine Learning models on the Web</h1> 
    <p id="w3c-state"> <time class="dt-published" datetime="2024-05-13">13 May 2024</time></p>
    <details open="">
      <summary>More details about this document</summary>
      <dl>
        
        <dt>Latest published version:</dt><dd>
                <a href="https://www.w3.org/reports/ai-web-impact/">https://www.w3.org/reports/ai-web-impact/</a>
              </dd>
        
        <dt>History:</dt><dd>
                    <a href="https://github.com/w3c/ai-web-impact/commits/">Commit history</a>
                  </dd>
        
        
        
        
        
        <dt>Editor:</dt><dd class="editor p-author h-card vcard">
    <span class="p-name fn">Dominique Hazael-Massieux</span>
  </dd>
        
        
        <dt>Feedback:</dt><dd>
        <a href="https://github.com/w3c/ai-web-impact/">GitHub w3c/ai-web-impact</a>
        (<a href="https://github.com/w3c/ai-web-impact/pulls/">pull requests</a>,
        <a href="https://github.com/w3c/ai-web-impact/issues/new/choose">new issue</a>,
        <a href="https://github.com/w3c/ai-web-impact/issues/">open issues</a>)
      </dd>
        
        <dt>Translations</dt><dd>
    <a href="index-zh.html">简体中文 (Simplified Chinese)</a>
  </dd>
      </dl>
    </details>
    
    
    <p class="copyright">
    <a href="https://www.w3.org/policies/#copyright">Copyright</a>
    ©
    2024
    
    <a href="https://www.w3.org/">World Wide Web Consortium</a>.
    <abbr title="World Wide Web Consortium">W3C</abbr><sup>®</sup>
    <a href="https://www.w3.org/policies/#Legal_Disclaimer">liability</a>,
    <a href="https://www.w3.org/policies/#W3C_Trademarks">trademark</a> and
    <a rel="license" href="https://www.w3.org/copyright/software-license-2023/" title="W3C Software and Document Notice and License">permissive document license</a> rules apply.
  </p>
    <hr title="Separator for header">
  </div>

<section id="abstract" class="introductory"><h2>Abstract</h2>
<p>
This document proposes an analysis of the systemic impact of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-1">AI systems</a>, and in particular ones based on <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-1">Machine Learning models</a>, on the Web, and the role that Web standardization may play in managing that impact.
</p>
</section>
<section id="sotd" class="introductory"><h2>Status of This Document</h2>
<p>
This document is intended to capture the current shared understanding of the <a href="https://www.w3.org/staff/"><abbr title="World Wide Web Consortium">W3C</abbr> Team</a> on the current and expected impact of developments linked to <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-2">Artificial Intelligence systems</a> on the Web, and identifying explorations the World Wide Web Consortium  community has started or ought to be starting, to manage that impact. It does not represent any consensus from the <abbr title="World Wide Web Consortium">W3C</abbr> Membership nor is it a standardization document.
</p>
<p>
 The document was authored by Dominique Hazaël-Massieux (<a href="mailto:dom@w3.org">dom@w3.org</a>), with significant contributions from the rest of the <abbr title="World Wide Web Consortium">W3C</abbr> Team.</p>
<p>
This document aims first and foremost to help structure discussions on what may be needed at the standardization level to make the systemic impact of AI (and specifically, <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-2">Machine Learning models</a>) less harmful or more manageable. It is bound to be incomplete and sometimes wrong - we are gathering input and feedback in <a href="https://github.com/w3c/ai-web-impact/issues">GitHub</a>, preferably before June 30, 2024.
</p>
<p>
Depending on the feedback received, possible next steps include more in-depth stakeholder interviews, a dedicated <abbr title="World Wide Web Consortium">W3C</abbr> Workshop, or developing a standardization roadmap.</p>

</section><nav id="toc"><h2 class="introductory" id="table-of-contents">Table of Contents</h2><ol class="toc"><li class="tocline"><a class="tocxref" href="#abstract">Abstract</a></li><li class="tocline"><a class="tocxref" href="#sotd">Status of This Document</a></li><li class="tocline"><a class="tocxref" href="#executive-summary"><bdi class="secno">1. </bdi>Executive Summary</a></li><li class="tocline"><a class="tocxref" href="#introduction"><bdi class="secno">2. </bdi>Introduction</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#terminology"><bdi class="secno">2.1 </bdi>Terminology</a></li></ol></li><li class="tocline"><a class="tocxref" href="#intersections-between-ai-systems-and-the-web"><bdi class="secno">3. </bdi>Intersections between AI systems and the Web</a></li><li class="tocline"><a class="tocxref" href="#ethics-and-societal-impact"><bdi class="secno">4. </bdi>Ethics and societal impact</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#respecting-autonomy-and-transparency"><bdi class="secno">4.1 </bdi>Respecting <span class="formerLink">autonomy</span> and <span class="formerLink">transparency</span></a><ol class="toc"><li class="tocline"><a class="tocxref" href="#transparency-on-ai-generated-content"><bdi class="secno">4.1.1 </bdi>Transparency on AI-generated content</a></li><li class="tocline"><a class="tocxref" href="#transparency-on-ai-mediated-services"><bdi class="secno">4.1.2 </bdi>Transparency on AI-mediated services</a></li></ol></li><li class="tocline"><a class="tocxref" href="#right-to-privacy-and-data-control"><bdi class="secno">4.2 </bdi>Right to <span class="formerLink">privacy and data control</span></a></li><li class="tocline"><a class="tocxref" href="#safety-and-security"><bdi class="secno">4.3 </bdi><span class="formerLink">Safety and security</span></a></li><li class="tocline"><a class="tocxref" href="#sustainability"><bdi class="secno">4.4 </bdi><span class="formerLink">Sustainability</span></a></li><li class="tocline"><a class="tocxref" href="#balancing-content-creators-incentives-and-consumers-rights"><bdi class="secno">4.5 </bdi>Balancing content creators incentives and consumers rights</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#comparison-with-search-engines"><bdi class="secno">4.5.1 </bdi>Comparison with search engines</a></li></ol></li></ol></li><li class="tocline"><a class="tocxref" href="#interop"><bdi class="secno">5. </bdi>Impact of <span data-link-type="dfn|abstract-op" class="formerLink">AI systems</span> on interoperability</a></li><li class="tocline"><a class="tocxref" href="#references"><bdi class="secno">A. </bdi>References</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#informative-references"><bdi class="secno">A.1 </bdi>Informative references</a></li></ol></li></ol></nav>

<section id="executive-summary"><div class="header-wrapper"><h2 id="x1-executive-summary"><bdi class="secno">1. </bdi>Executive Summary</h2><a class="self-link" href="#executive-summary" aria-label="Permalink for Section 1."></a></div>
  

  <p><a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-3">Machine Learning models</a> support a new generation of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-3">AI systems</a>. These models are often <a data-link-type="dfn|abstract-op" data-lt="training" href="#dfn-training" class="internalDFN" id="ref-for-dfn-training-1">trained</a> on a large amount of Web content, deployed at scale through web interfaces, and can be used to generate plausible content at unprecedented speed and cost.</p>
  <p>Given the scope and scale of these intersections, this wave of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-4">AI systems</a> is having potential systemic impact on the Web and some of the equilibriums on which its ecosystem had grown.</p>
  <p>This document reviews these intersections through their ethical, societal and technical impacts and highlights a number of areas where standardization, guidelines and interoperability could help manage these changes:</p>
  <ul>
    <li>a <a href="#b7">consent mechanism for the use of Web content in training pipelines</a>,</li>
    <li><a href="#b1">labeling content as computer-generated</a>,</li>
    <li><a href="#b2">surfacing training sources in model cards</a>,</li>
    <li><a href="#b3">exposing model-backed Web APIs</a>,</li>
    <li><a href="#b4">personal data stores</a> to reduce risk of private data exposure,</li>
    <li><a href="#b5">strengthening credentials and identity mechanisms</a> in light of new impersonation risks,</li>
    <li>an <a href="#b6">evaluation framework for the environmental impact of Web standards</a>,</li>
    <li>a <a href="#b8">framework to manage interoperability based on model inference</a>, including for non-deterministic models.</li>
  </ul>
  <p>We are <a href="https://github.com/w3c/ai-web-impact/issues">seeking input</a> from the community on proposals that could help make progress on these topics, and on other topics that this document has failed to identify.</p>
</section>

<section id="introduction"><div class="header-wrapper"><h2 id="x2-introduction"><bdi class="secno">2. </bdi>Introduction</h2><a class="self-link" href="#introduction" aria-label="Permalink for Section 2."></a></div>



<p>
Recent developments in the decades-long computer science field of Artificial Intelligence have made a number of systems emerge that already have started having <strong>systemic</strong> impacts on the Web and can be expected to further transform a number of shared expectations on which the health of the Web had relied so far.
</p>
<p>
To help structure a conversation within the <abbr title="World Wide Web Consortium">W3C</abbr> community (and possibly with other Web-related standards organization) about these transformations, this document collects the current shared understanding among the <abbr title="World Wide Web Consortium">W3C</abbr> Team of the intersections of "<a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence" class="internalDFN" id="ref-for-dfn-artificial-intelligence-1">Artificial Intelligence</a>", more specifically in the field of <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-4">Machine Learning models</a> (including Large Language Models and other so called generative AI models), with the Web as a system, and ongoing <abbr title="World Wide Web Consortium">W3C</abbr> development in this space. It is also a goal to raise questions about additional explorations that may be needed as further developments in this space arise.
</p>
<p>
That current understanding is bound to be incomplete or sometimes plain wrong; we hope that by publishing this document and inviting community reviews on it, we iteratively improve this shared understanding and help build a community roadmap to increase the positive impact and decrease the harms that are emerging in this intersection.
</p>
<section id="terminology"><div class="header-wrapper"><h3 id="x2-1-terminology"><bdi class="secno">2.1 </bdi>Terminology</h3><a class="self-link" href="#terminology" aria-label="Permalink for Section 2.1"></a></div>



<p>
The term "Artificial Intelligence" covers a very broad spectrum of algorithms, techniques and technologies. [<cite><a class="bibref" data-link-type="biblio" href="#bib-iso/iec-22989" title="Artificial intelligence concepts and terminology">ISO/IEC-22989</a></cite>] defines <dfn id="dfn-artificial-intelligence" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Artificial Intelligence</dfn> as "research and development of mechanisms and applications of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-5">AI systems</a>", with <dfn data-lt="Artificial Intelligence system|AI system" data-plurals="ai systems|artificial intelligence systems" id="dfn-artificial-intelligence-system" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">AI system</dfn>s being "an engineered system that generates outputs such as content, forecasts, recommendations or decisions for a given set of human-defined objectives". At the time of the writing of this document in early 2024, the gist of the Web ecosystem conversation on Artificial Intelligence is mostly about systems based on <dfn id="dfn-machine-learning" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Machine Learning</dfn> ("process of optimizing model parameters through computational techniques, such that the model's behavior reflects the data or experience") and its software manifestation, <dfn data-lt="model|Machine Learning model" data-plurals="machine learning models" id="dfn-model" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Machine Learning model</dfn>s ("mathematical construct that generates an inference or prediction based on input data or information").
</p>
<p>
While we acknowledge the much broader meaning of Artificial Intelligence and its intersection with a number of other Web- and <abbr title="World Wide Web Consortium">W3C</abbr>-related activities (e.g., the Semantic Web and Linked Data), this document willfully focuses only on the current conversation around the impact that these <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-5">Machine Learning models</a> are bringing to the Web. We further acknowledge that this document has been developed during, and is partially a response to, a cycle of inflated expectations and investments in that space. That situation underlines the need for a framework to structure the conversation.
</p>
<p>
Because of this focus on <a data-link-type="dfn|abstract-op" href="#dfn-machine-learning" class="internalDFN" id="ref-for-dfn-machine-learning-1">Machine Learning</a>, this document analyzes AI impact through the two main phases needed to operate <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-6">Machine Learning models</a>: <dfn id="dfn-training" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">training</dfn> ("process to determine or to improve the parameters of a Machine Learning model, based on a Machine Learning algorithm, by using training data") and <dfn data-lt="run|running|inference" id="dfn-run" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">inference</dfn> (the actual usage of these models to produce their expected outcomes), which we also casually refer as running a model.
</p>
</section>
</section>
<section id="intersections-between-ai-systems-and-the-web"><div class="header-wrapper"><h2 id="x3-intersections-between-ai-systems-and-the-web"><bdi class="secno">3. </bdi>Intersections between AI systems and the Web</h2><a class="self-link" href="#intersections-between-ai-systems-and-the-web" aria-label="Permalink for Section 3."></a></div>



<p>
A major role the Web plays is as a platform for content creators to expose at scale their content to content consumers. AI directly relates to these two sides of the platform:
</p>
<ul>

<li>In a number of cases, models are trained based on content crawled from the Web; the combination of scale and structure in that content (made possible by the underlying standards) has made it an invaluable source of training data that backs some of the most visible results in recent AI developments, such as large language models or image/video generators;

</li><li>Conversely, a number of these AI models can be used to generate content at unprecedented scale, which the reach of the Web allows to deploy seamlessly to the billions of users of the platform.
</li>
</ul>
<p>
When looking more specifically at the browser-mediated part of the Web which remains primarily a client/server architecture, AI models can be <a data-link-type="dfn|abstract-op" href="#dfn-run" class="internalDFN" id="ref-for-dfn-run-1">run</a> either on the server-side or on the client-side (and somewhat more marginally at this point, in a <a href="https://github.com/webmachinelearning/proposals/issues/5">hybrid-fashion between the two</a>). On the client side, they can either be provided and operated by the browser (either at the user's request, or at the application's request), or entirely by the client-side application itself.
</p>
<p>
It's also worth noting that as <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-6">AI systems</a> are gaining rapid adoption, their intersection with the Web is bound to evolve and possibly trigger new systemic impact; for instance, emerging <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-7">AI systems</a> that combine <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-7">Machine Learning models</a> and content loaded from the Web in real-time may induce revisiting in depth the role and user experience of Web browsers in consuming or searching content.
</p>
</section>
<section id="ethics-and-societal-impact"><div class="header-wrapper"><h2 id="x4-ethics-and-societal-impact"><bdi class="secno">4. </bdi>Ethics and societal impact</h2><a class="self-link" href="#ethics-and-societal-impact" aria-label="Permalink for Section 4."></a></div>



<p>
The <a href="https://www.w3.org/TR/ethical-web-principles/"><abbr title="World Wide Web Consortium">W3C</abbr>'s Technical Architecture Group Ethical Web Principles</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-ethical-web-principles" title="Ethical Web Principles">ethical-web-principles</a></cite>] includes ensuring "<a href="https://www.w3.org/TR/ethical-web-principles/#noharm">the Web should not cause harm to society</a>".
</p>
<p>
As described above, the Web is already a key enabler in some of the recent developments in Artificial Intelligence, and the usage and impact of Artificial Intelligence is being multiplied in scale through its distribution via the Web. This calls for the <abbr title="World Wide Web Consortium">W3C</abbr> community as stewards of the Web to understand potential harms emerging from that combination and to identify potential mitigations to these harms.
</p>
<p>
The <a href="https://www.w3.org/TR/webmachinelearning-ethics/">Ethical Principles for Web Machine Learning</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-webmachinelearning-ethics" title="Ethical Principles for Web Machine Learning">webmachinelearning-ethics</a></cite>] started in the <a href="https://www.w3.org/groups/wg/webmachinelearning">Web Machine Learning Working Group</a> combine values and principles from the UNESCO <a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455">Recommendation on the Ethics of Artificial Intelligence</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-unesco-ai" title="Recommendation on the Ethics of Artificial Intelligence">UNESCO-AI</a></cite>] with Web-specific principles from the Ethical Web Principles to identify 4 values and 11 principles that integration of Machine Learning on the Web should follow, and which have helped structure this document.
</p>
<section id="respecting-autonomy-and-transparency"><div class="header-wrapper"><h3 id="x4-1-respecting-autonomy-and-transparency"><bdi class="secno">4.1 </bdi>Respecting <a href="https://www.w3.org/TR/webmachinelearning-ethics/#principle-3-autonomy">autonomy</a> and <a href="https://www.w3.org/TR/webmachinelearning-ethics/#principle-6-transparency-and-explainability">transparency</a></h3><a class="self-link" href="#respecting-autonomy-and-transparency" aria-label="Permalink for Section 4.1"></a></div>

<section id="transparency-on-ai-generated-content"><div class="header-wrapper"><h4 id="x4-1-1-transparency-on-ai-generated-content"><bdi class="secno">4.1.1 </bdi>Transparency on AI-generated content</h4><a class="self-link" href="#transparency-on-ai-generated-content" aria-label="Permalink for Section 4.1.1"></a></div>




<p>
Recent <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-8">AI systems</a> are able to assist in the partial or complete creation of content (textual, graphic, audio and video) at a level of (at least superficially) credible quality and in quantities beyond that developed by humans. This provides both opportunities and risks for content creators, but more importantly, it creates a systemic risk for content consumers in no longer being able to distinguish or discover authoritative or curated content in a sea of credible (but either possibly or willfully wrong) generated content.
</p>
<p>
That need is pressing directly for end-users as they individually consume content, but also applies to agents that end-users rely on: typically, search engines would likely benefit from transparency on purely AI generated content. Somewhat ironically, crawlers used to train AI models are likely to need such a signal as well, since <a data-link-type="dfn|abstract-op" href="#dfn-training" class="internalDFN" id="ref-for-dfn-training-2">training</a> models on the output of models may create unexpected and unwanted results.
</p>
<p>
We do not know of any solution that could guarantee (e.g., through cryptography) that a given piece of content was or was not generated (partially or entirely) by <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-9">AI systems</a>. That gap unfortunately leaves a systemic risk in terms of misinformation and spam that should be of grave concern for the health of the Web as a content distribution platform and of society as a whole.
</p>
<div id="b1" class="advisement">
<p>
A plausible role of standards in this space would be to at least facilitate the <strong>labeling of content</strong> to indicate whether it is the result of a <strong>computer-generated process</strong>. While such labels are unlikely to be enforceable through technical means, they could gain broad adoption with a combination of being automatically added by <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-10">AI systems</a> (possibly with enough friction that removing them would be at least somewhat costly at scale), and possibly serve as hooks in the regulatory context.
</p>
<p>
A number of proposals have already emerged in this space, which may benefit from more visibility, discussion and ultimately, scalable deployment:
</p>
<ul>
<li><a href="https://c2pa.org/specifications/specifications/1.3/ai-ml/ai_ml.html">C2PA Guidance for AI and Machine Learning</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-c2pa-ai" title="Guidance for Artificial Intelligence and Machine Learning">C2PA-AI</a></cite>]

</li><li><a href="https://iptc.org/news/iptc-releases-draft-of-digital-source-type-vocabulary-to-support-synthetic-media/">IPTC synthetic media</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-iptc-dst" title="Digital Source Type vocabulary">IPTC-DST</a></cite>] and its matching representation in <a href="https://github.com/schemaorg/schemaorg/issues/3392">Schema.org</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-schema-org" title="Schema.org">schema-org</a></cite>]

</li><li><a href="https://github.com/whatwg/html/issues/9479">Proposal: Meta Tag for AI Generated Content</a> in [<cite><a class="bibref" data-link-type="biblio" href="#bib-html" title="HTML Standard">HTML</a></cite>] (individual submission)
</li>
</ul>
<p>
An area that could be explored is role Web browsers might play in surfacing labelling or provenance information of content, e.g., embedded content such as images or video. This can currently be done by publishers' websites or independent verifiers, but integrating this capability into the browser could make the information more convenient for users to access, as well as being independent of any particular publisher or website where the same content may be viewed.
</p>
</div>
</section>
<section id="transparency-on-ai-mediated-services"><div class="header-wrapper"><h4 id="x4-1-2-transparency-on-ai-mediated-services"><bdi class="secno">4.1.2 </bdi>Transparency on AI-mediated services</h4><a class="self-link" href="#transparency-on-ai-mediated-services" aria-label="Permalink for Section 4.1.2"></a></div>



<p>
A well-known issue with relying operationally on <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-8">Machine Learning models</a> is that they will integrate and possibly strengthen any <dfn id="dfn-bias" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">bias</dfn> ("systematic difference in treatment of certain objects, people or groups in comparison to others" [[[<cite><a class="bibref" data-link-type="biblio" href="#bib-iso/iec-22989" title="Artificial intelligence concepts and terminology">ISO/IEC-22989</a></cite>]) in the data that was used during their <a data-link-type="dfn|abstract-op" href="#dfn-training" class="internalDFN" id="ref-for-dfn-training-3">training</a>. <a data-link-type="dfn|abstract-op" href="#dfn-bias" class="internalDFN" id="ref-for-dfn-bias-1">Bias</a> commonly occurs in other algorithms and human decision processes. Where <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-11">AI systems</a> make that <a data-link-type="dfn|abstract-op" href="#dfn-bias" class="internalDFN" id="ref-for-dfn-bias-2">bias</a> a bigger challenge is because these models are at this point harder to audit and amend since they operate mostly as a closed box.
</p>
<p>
Such <a data-link-type="dfn|abstract-op" href="#dfn-bias" class="internalDFN" id="ref-for-dfn-bias-3">bias</a> will disproportionately affect users whose expected input or output is less well represented in training data (as e.g., discussed in the <a href="https://www.w3.org/WAI/research/ai2023/">report from the 2023 AI &amp; Accessibility research symposium</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-wai-ai" title="Artificial Intelligence (AI) and Accessibility Research Symposium 2023">WAI-AI</a></cite>]), which intuitively is likely to correlate strongly with users already disenfranchised by society and technology - e.g., if your language, appearance or behavior doesn't fit the mainstream-expected norm, you're less likely to feature in mainstream content and thus less visible or misrepresented in training data.
</p>
<p>
Until better tools emerge to facilitate at least the systematic detection of such <a data-link-type="dfn|abstract-op" href="#dfn-bias" class="internalDFN" id="ref-for-dfn-bias-4">bias</a>, encouraging and facilitating the systematic publication of information on whether a Machine Learning model is in use, and how such a model was trained and checked for <a data-link-type="dfn|abstract-op" href="#dfn-bias" class="internalDFN" id="ref-for-dfn-bias-5">bias</a> may help end-users make more informed choices about the services they use (which, of course, only helps if they have a choice in the first place, which may not apply e.g., to some government-provided services).
</p>
<div id="b2" class="advisement">
<p>
<a href="https://arxiv.org/pdf/1810.03993.pdf">Model cards for Model Reporting</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-model-cards" title="Model Cards for Model Reporting">MODEL-CARDS</a></cite>] are one of the approaches that were <a href="https://www.w3.org/2020/06/machine-learning-workshop/report.html#user">discussed in the 2020 <abbr title="World Wide Web Consortium">W3C</abbr> Workshop on Web and Machine Learning</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-w3c-ml-ws" title="W3C Workshop Report on Web and Machine Learning">W3C-ML-WS</a></cite>]. Assuming this reporting provides meaningful and actionable transparency, a question for (the) technical standardization would be how such <strong>cards should be serialized and made discoverable on the Web</strong>.
</p>
</div>
<div id="b3" class="advisement">
<p>
<abbr title="World Wide Web Consortium">W3C</abbr> should look at a particular category of model deployments: <strong>models that are used by browser engines themselves to fulfill API</strong> requests. A number of Web browser APIs already expose (more or less explicitly) output of <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-9">Machine Learning models</a>:
</p>
<ul>

<li><a href="https://wicg.github.io/speech-api/">Web Speech API</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-speech-api" title="Web Speech API">SPEECH-API</a></cite>]

</li><li><a href="https://wicg.github.io/shape-detection-api/">Accelerated Shape Detection API</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-shape-detection-api" title="Accelerated Shape Detection in Images">SHAPE-DETECTION-API</a></cite>]

</li><li><a href="https://w3c.github.io/mediacapture-extensions/#exposing-mediastreamtrack-source-background-blur-support">Background blur, face detection, gaze correction controls in Media capture</a>
</li>
</ul>
</div>
<p>
As described below, these APIs also raise engineering questions about how to ensure they provide the 

<a href="#interop">level of interoperability</a> that have been expected from more traditionally deterministic algorithms.
</p>
</section>
</section>

<section id="right-to-privacy-and-data-control"><div class="header-wrapper"><h3 id="x4-2-right-to-privacy-and-data-control"><bdi class="secno">4.2 </bdi>Right to <a href="https://www.w3.org/TR/webmachinelearning-ethics/#principle-4-right-to-privacy-and-data-protection">privacy and data control</a></h3><a class="self-link" href="#right-to-privacy-and-data-control" aria-label="Permalink for Section 4.2"></a></div>



<p>
Models trained on un-triaged or partially triaged content off the Web are bound to include personally identifiable information (PII). The same is true for models trained on data that users have chosen to share (for public consumption or not) with service providers. These models can often be made to retrieve and share that information with any user who knows how to ask, which breaks expectations of privacy for those whose personal information was collected, and is likely to be in breach with privacy regulations in a number of jurisdictions. Worse, they create risks for new types of attacks (see <a href="#safety-and-security" data-matched-text="[[[#safety-and-security]]]" class="sec-ref"><bdi class="secno">4.3 </bdi><span>Safety and security</span></a>).
</p>
<p>
  While the exclusion rules discussed in the context of content creation could partially help with the first situation, they would not help with the second one. This problem space is likely to be under heavy regulatory and legal scrutiny.</p>
  <p>From a technical standardization perspective, beyond labeling content, the emergence of user data being repurposed for model <a data-link-type="dfn|abstract-op" href="#dfn-training" class="internalDFN" id="ref-for-dfn-training-4">training</a> and some of the pushback it is generating may bring renewed momentum (from user and service provider alike) behind decentralized architectures that leave user data under less centralized control (as illustrated by the recent widening adoption of Activity Streams).</p>
<div id="b4" class="advisement">
  <p>A particularly relevant instance of that pattern is emerging with so-called <strong>personal data stores</strong>: these provide ways for users to exert more fine-grained control of their data, by separating more clearly the roles of data store and data processor (which, in a traditional cloud infrastructure, would otherwise typically be handled by a single entity). 
</p>

<p>
That topic has most recently surfaced in <abbr title="World Wide Web Consortium">W3C</abbr> through the <a href="https://lists.w3.org/Archives/Public/public-new-work/2023Sep/0007.html">proposed charter for a SOLID Working Group</a> late 2023 (a charter that the <abbr title="World Wide Web Consortium">W3C</abbr> community has recognized as important, but where there is not yet consensus).
</p>
</div>

<p>
Allowing to <a data-link-type="dfn|abstract-op" href="#dfn-run" class="internalDFN" id="ref-for-dfn-run-2">run</a> a model on personal data without uploading that data to a server is one of the key motivations behind the browser <a href="https://www.w3.org/TR/webnn/">Web Neural Network API</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-webnn" title="Web Neural Network API">WEBNN</a></cite>] which, completing the computing capabilities already provided by <a href="https://www.w3.org/groups/wg/wasm/">WebAssembly</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-wasm-core-2" title="WebAssembly Core Specification">WASM-CORE-2</a></cite>] and <a href="https://www.w3.org/groups/wg/gpu/">WebGPU</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-webgpu" title="WebGPU">WEBGPU</a></cite>], provides additional Machine Learning specific optimizations to <a data-link-type="dfn|abstract-op" href="#dfn-run" class="internalDFN" id="ref-for-dfn-run-3">run</a> models efficiently from within the browser (and thus, on the end-user device). 
</p>
</section>
<section id="safety-and-security"><div class="header-wrapper"><h3 id="x4-3-safety-and-security"><bdi class="secno">4.3 </bdi><a href="https://www.w3.org/TR/webmachinelearning-ethics/#principle-5-safety-and-security">Safety and security</a></h3><a class="self-link" href="#safety-and-security" aria-label="Permalink for Section 4.3"></a></div>



<p>
A number of <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-10">Machine Learning models</a> have significantly lowered the cost of generating credible textual, as well as audio and video (real-time or recorded) impersonations of real persons. This creates significant risks of upscaling the capabilities of phishing and other types of frauds, and thus raising much higher the barriers to establish trust in online interactions. If users no longer feel safe in their digitally-mediated interactions, the Web will no longer be able to play its role as a platform for these interactions.
</p>
<div id="b5" class="advisement">
<p>
This points towards even stronger needs for <strong>robust identity and credential management</strong> on the Web. The work of the <a href="https://www.w3.org/2017/vc/WG/">Verifiable Credentials Working Group</a> allows to express credentials in a cryptographically secure, privacy-preserving, and machine-verifiable way [<cite><a class="bibref" data-link-type="biblio" href="#bib-vc-data-model" title="Verifiable Credentials Data Model v1.1">VC-DATA-MODEL</a></cite>]. The <a href="https://lists.w3.org/Archives/Public/public-new-work/2024Jan/0006.html">proposed work to better integrate Federated Identity systems into browsers</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-fedcm" title="Federated Credential Management API">FEDCM</a></cite>] and the <a href="https://wicg.github.io/digital-identities/">emerging one on surfacing digital credentials to Web content</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-digital-credentials" title="Digital Credentials">DIGITAL-CREDENTIALS</a></cite>] are likely part of mitigating the risks associated with these new impersonation threats.
</p>
</div>
</section>
<section id="sustainability"><div class="header-wrapper"><h3 id="x4-4-sustainability"><bdi class="secno">4.4 </bdi><a href="https://www.w3.org/TR/webmachinelearning-ethics/#principle-8-sustainability">Sustainability</a></h3><a class="self-link" href="#sustainability" aria-label="Permalink for Section 4.4"></a></div>



<p>
<a data-link-type="dfn|abstract-op" href="#dfn-training" class="internalDFN" id="ref-for-dfn-training-5">Training</a> and <a data-link-type="dfn|abstract-op" href="#dfn-run" class="internalDFN" id="ref-for-dfn-run-4">running</a> <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-11">Machine Learning models</a> can prove very resource-intensive, in particular in terms of power- and water-consumption. The imperative of reducing humanity's footprint on natural resources should apply particularly strongly to the technologies that standardization helps deploy at scale. 
</p>
<p>There is relatively new but promising work in the <a href="https://www.w3.org/community/sustyweb/">Sustainable Web Design Community Group</a> (a <a href="https://lists.w3.org/Archives/Public/public-new-work/2024Mar/0000.html">candidate to become a standardization Working Group</a>) to explain how to <a href="https://www.w3.org/blog/2023/introducing-web-sustainability-guidelines/">use Web technologies in a sustainable way</a>.</p>
<p> The <a href="https://github.com/Green-Software-Foundation/sci"> Green Software Foundation Software Carbon Intensity Working Group </a> is developing a score to calculate carbon footprint of software applications. </p>
<div id="b6" class="advisement">
<p><abbr title="World Wide Web Consortium">W3C</abbr> still lacks a well-defined <strong>framework to evaluate the environmental impact of its standards</strong>. Given the documented high environmental impact of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-12">AI systems</a>, it will surely become more important that <abbr title="World Wide Web Consortium">W3C</abbr> groups that are expected to accelerate the deployment of <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-12">Machine Learning models</a> take a proactive approach in exploring and documenting how they envision the environmental impact of their work, and possible mitigations they might identify.</p>
</div>
</section>
<section id="balancing-content-creators-incentives-and-consumers-rights"><div class="header-wrapper"><h3 id="x4-5-balancing-content-creators-incentives-and-consumers-rights"><bdi class="secno">4.5 </bdi>Balancing content creators incentives and consumers rights</h3><a class="self-link" href="#balancing-content-creators-incentives-and-consumers-rights" aria-label="Permalink for Section 4.5"></a></div>




<p>
Some of the largest and most visible <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-13">Machine Learning models</a> are known or assumed to have been trained with materials crawled from the Web, without the explicit consent of their creators or publishers.
</p>
<p>
The controversy that has emerged from that situation is being debated (and in some cases, arbitrated) through the lens of copyright law.
</p>
<p>
It is not our place to determine if and how various copyright legislation bears on that particular usage. Beyond legal considerations, the copyright system creates a (relatively) shared understanding between creators and consumers that, by default, content cannot be redistributed, remixed, adapted or built upon without creators' consent. This shared understanding made it possible for a lot of content to be openly distributed on the Web. It also allowed creators to consider a variety of monetization options (subscription, pay per view, advertising) for their content grounded on the assumption that consumers will always reach their pages.
</p>
<p>
A number of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-13">AI systems</a> combine (1) automated large-scale consumption of Web content, and (2) production at scale of content, in ways that do not recognize or otherwise compensate content it was trained from.
</p>
<p>
 
</p>
<p>
While some of these tensions are not new (as discussed below), systems based on Machine Learning are poised to upend the existing balance. Unless a new sustainable equilibrium is found, this exposes the Web to the following undesirable outcomes:
</p>
<ul>

<li>Significantly less open distributed content (which would likely have a disproportionate impact on the less wealthy part of the population)

</li><li>A less appealing platform to distribute content
</li>
</ul>
<p>
A less direct risk may emerge from changes in copyright laws meant to help to rebalance the situation but which would reduce the rights from content consumers and then undermine the value of the Web as a platform for which content distribution is a key value proposition.
</p>
<section id="comparison-with-search-engines"><div class="header-wrapper"><h4 id="x4-5-1-comparison-with-search-engines"><bdi class="secno">4.5.1 </bdi>Comparison with search engines</h4><a class="self-link" href="#comparison-with-search-engines" aria-label="Permalink for Section 4.5.1"></a></div>



<p>
A number of the tensions emerging around the re-use of content crawled at scale from the Web have a long history given the central role that search engines play for the Web. Indeed, search engines provide (and absorb) value from their ability to retrieve and organize information from content on the Web, and they heavily rely on the standardized infrastructure this content is built on to achieve these results.
</p>
<p>
The more or less implicit contract that emerged between search engines and content providers has been that search engines can retrieve, parse and partially display content from the providers, in exchange of bringing more visibility and traffic to them. A further assumption has been encoded in the way the Web operates that this contract is the default for anyone making content available publicly on the Web, with an opt-out mechanism encoded via the <a href="https://www.rfc-editor.org/rfc/rfc9309.html"><code>robots.txt</code> directives</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-rfc9309" title="Robots Exclusion Protocol">RFC9309</a></cite>].
</p>
<p>
Over time, in addition to the links to sites matching the user's query, search engines have integrated more ways to surface content directly from the target Web sites: either through rich snippets (typically made possible by the use of schema.org metadata) or through embedded preview (e.g., what the <a href="https://amp.dev/">AMP project</a> enabled). These changes were frequently accompanied by sometimes challenging discussions around the balance between bringing additional visibility to crawled content and reducing the incentive from end-users to visit the source website (e.g., because they may have already received sufficient information from the search results page).
</p>
<p>
In a certain number of cases, <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-14">AI systems</a> are used as an alternative or complement to what users would traditionally have used a search engine for (and indeed, are increasingly integrated into search engine interfaces). So it seems useful to explore to what extent the lessons learned from the evolutionary process balancing the needs from search engines and from content creators can inform the discussion on crawlers used to train <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-14">Machine Learning models</a>.
</p>
<p>
In making that comparison, it's also important to note significant differences:
</p>
<ul>

<li>The implicit contract that content creators expect from search engines crawlers –i.e., that they will bring exposure to their content– does not have a systematic equivalent for content integrated into <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-15">AI systems</a>; while some such systems are gaining the ability to point back to the source of their training data used in a given <a data-link-type="dfn|abstract-op" href="#dfn-run" class="internalDFN" id="ref-for-dfn-run-5">inference</a>, this is hardly a widespread feature of these systems, nor is it obvious it could be applied systematically (e.g., would linking back to sources for a generated image even make sense?); even if it could, fewer sources would likely be exposed than in a typical search engine results page, and the incentives for the user to follow the links would likely be substantially lower.

</li><li><code>robots.txt</code> directives allow specific rules to be given to specific crawlers based on their user agent; while this has been practically manageable when dealing with (for better or for worse) few well-known search engine crawlers, expecting content creators to maintain potential allow- and block-lists of the rapidly expanding number of crawlers deployed to retrieve training data seems unlikely to achieve sustainable results.
</li>
</ul>
<p>
Given the likely different expectations around the quid-pro-quo of crawling in the context of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-16">AI systems</a>, it is not obvious that the permission-less pattern inherited from the early days of the Web (robots.txt was designed in 1994) would be a satisfactory match to ensure the long term sustainability of content publication on the Web (itself presumably in the long term interest of AI crawlers themselves).
</p>
<div id="b7" class="advisement">
<p>
In general, a possibly helpful line of inquiry for standards in this space would be to identify solutions that help <strong>content producers and AI crawlers to find agreeable terms, ideally at a scale</strong> that would make it appealing to all parties.
</p>
<p>
Several groups and individuals have been exploring how to make it possible for content publishers to express their willingness to get their content used for <a data-link-type="dfn|abstract-op" href="#dfn-training" class="internalDFN" id="ref-for-dfn-training-6">training</a> <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-15">Machine Learning models</a>:
</p>
<ul>

<li>The <a href="https://www.w3.org/groups/cg/tdmrep">Text and Data Mining Reservation Protocol Community Group</a> has developed the <a href="https://www.w3.org/community/reports/tdmrep/CG-FINAL-tdmrep-20240202/">TDM Reservation Protocol (TDMRep)</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-tdmrep" title="Final Community Group Report">TDMRep</a></cite>] to "express the reservation of rights relative to text &amp; data mining applied to lawfully accessible Web content"

</li><li>Discussions are starting <a href="https://mailarchive.ietf.org/arch/browse/ai-control/">in IETF around updating the robots.txt directives</a> in this context; among others, the <a href="https://www.w3.org/community/robotstxt/">update robots.txt Community Group</a> proposes to add an opt-in mechanism to the robots.txt directives.
</li>
<li>The <a href="https://journallist.net/">JournalList</a> association is looking into revising their <code>trust.txt</code> [<cite><a class="bibref" data-link-type="biblio" href="#bib-trust.txt" title="Specification for trust.txt file and underlying system">TRUST.TXT</a></cite>] to <a href="https://journallist.net/new-tool-to-deal-with-ai">let publishers express whether their content can be used for training models</a></li>

</ul>
</div>
</section>
</section>
</section>
<section id="impact-of-ai-systems-on-interoperability"><div class="header-wrapper"><h2 id="interop"><bdi class="secno">5. </bdi>Impact of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" class="internalDFN" id="ref-for-dfn-artificial-intelligence-system-17">AI systems</a> on interoperability</h2><a class="self-link" href="#interop" aria-label="Permalink for Section 5."></a></div>



<p>
  A key part of <a href="https://www.w3.org/TR/w3c-vision/#vision-web"><abbr title="World Wide Web Consortium">W3C</abbr>'s vision for the Web</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-w3c-vision" title="Vision for W3C">w3c-vision</a></cite>] is to ensure the Web is developed around principles of interoperability: that is, for technologies that <abbr title="World Wide Web Consortium">W3C</abbr> codifies as Web standards, to ensure they are implemented and deployed in a way that will work the same across products, allowing for greater choice for users and fostering the long term viability of the content.</p>
<p>When the algorithm on which interoperability relies is deterministic, ensuring interoperability is a matter of describing in sufficient detail and clarity the said algorithm, and running sufficient testing on the products to verify they achieve the intended result. The move to more <a href="https://www.w3.org/TR/design-principles/#algorithms">algorithmic specifications</a> [<cite><a class="bibref" data-link-type="biblio" href="#bib-design-principles" title="Web Platform Design Principles">design-principles</a></cite>] and thorough automated testing (e.g., through the <a href="https://web-platform-tests.org/">Web Platform Tests project</a>) has largely been driven by the goal of providing a robust interoperable platform.
</p>
<div id="b8" class="advisement">
<p>
As discussed above, <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-16">Machine Learning models</a> are already finding their way into standardized Web APIs. These creates two challenges to our interoperability goals:
</p>
<ul>

<li><a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-17">Machine Learning models</a> are mostly not built or described as a series of algorithmic steps. If a given standardized behavior is expected to be best fulfilled by <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-18">Machine Learning models</a>, how should that behavior be specified? How can it be tested to a level that sufficiently verifies an <strong>interoperable outcome across products that would use different models</strong>? What impact would it have on the fingerprinting surface of the browsers?

</li><li>A number of important <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-19">Machine Learning models</a> are not deterministic; if or when some of these <strong>non-deterministic models</strong> get exposed in standardized APIs, this consistency question is no longer limited to two products using two different models, since a given input would no longer produce a predetermined output. It is not clear to us at the moment how to prepare for interoperable behaviors based on non-deterministic models, which probably raises the question of whether and how such models should be acceptable as part of interoperable implementations.
</li>
</ul>
</div>
<p>
A possible consequence of these challenges is a reduction of the scope of what can be meaningfully made interoperable and standardized as a possibly growing number of features get mediated by <a data-link-type="dfn|abstract-op" href="#dfn-model" class="internalDFN" id="ref-for-dfn-model-20">Machine Learning models</a> (similar to the <a href="https://datatracker.ietf.org/doc/html/draft-tschofenig-post-standardization-02">postulated impact of growing capabilities of web applications on the need to standardize protocols</a>). In that context, discussions e.g., around AI-based codecs point towards possible significant changes in the interoperability landscape.
</p>
</section>


<section id="references" class="appendix"><div class="header-wrapper"><h2 id="a-references"><bdi class="secno">A. </bdi>References</h2><a class="self-link" href="#references" aria-label="Permalink for Appendix A."></a></div><section id="informative-references"><div class="header-wrapper"><h3 id="a-1-informative-references"><bdi class="secno">A.1 </bdi>Informative references</h3><a class="self-link" href="#informative-references" aria-label="Permalink for Appendix A.1"></a></div>
    
    <dl class="bibliography"><dt id="bib-c2pa-ai">[C2PA-AI]</dt><dd>
      <a href="https://c2pa.org/specifications/specifications/1.3/ai-ml/ai_ml.html"><cite>Guidance for Artificial Intelligence and Machine Learning</cite></a>.  C2PA. URL: <a href="https://c2pa.org/specifications/specifications/1.3/ai-ml/ai_ml.html">https://c2pa.org/specifications/specifications/1.3/ai-ml/ai_ml.html</a>
    </dd><dt id="bib-design-principles">[design-principles]</dt><dd>
      <a href="https://www.w3.org/TR/design-principles/"><cite>Web Platform Design Principles</cite></a>. Sangwhan Moon; Lea Verou.  W3C. 30 January 2024. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/design-principles/">https://www.w3.org/TR/design-principles/</a>
    </dd><dt id="bib-digital-credentials">[DIGITAL-CREDENTIALS]</dt><dd>
      <a href="https://wicg.github.io/digital-identities/"><cite>Digital Credentials</cite></a>.  WICG. March 2024. URL: <a href="https://wicg.github.io/digital-identities/">https://wicg.github.io/digital-identities/</a>
    </dd><dt id="bib-ethical-web-principles">[ethical-web-principles]</dt><dd>
      <a href="https://www.w3.org/TR/ethical-web-principles/"><cite>Ethical Web Principles</cite></a>. Daniel Appelquist; Hadley Beeman; Amy Guy.  W3C. 19 March 2024. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/ethical-web-principles/">https://www.w3.org/TR/ethical-web-principles/</a>
    </dd><dt id="bib-fedcm">[FEDCM]</dt><dd>
      <a href="https://fedidcg.github.io/FedCM/"><cite>Federated Credential Management API</cite></a>.  W3C. Draft Community Group Report. URL: <a href="https://fedidcg.github.io/FedCM/">https://fedidcg.github.io/FedCM/</a>
    </dd><dt id="bib-html">[HTML]</dt><dd>
      <a href="https://html.spec.whatwg.org/multipage/"><cite>HTML Standard</cite></a>. Anne van Kesteren; Domenic Denicola; Ian Hickson; Philip Jägenstedt; Simon Pieters.  WHATWG. Living Standard. URL: <a href="https://html.spec.whatwg.org/multipage/">https://html.spec.whatwg.org/multipage/</a>
    </dd><dt id="bib-iptc-dst">[IPTC-DST]</dt><dd>
      <a href="https://cv.iptc.org/newscodes/digitalsourcetype/"><cite>Digital Source Type vocabulary</cite></a>.  IPTC. URL: <a href="https://cv.iptc.org/newscodes/digitalsourcetype/">https://cv.iptc.org/newscodes/digitalsourcetype/</a>
    </dd><dt id="bib-iso/iec-22989">[ISO/IEC-22989]</dt><dd>
      <a href="https://www.iso.org/standard/74296.html"><cite>Artificial intelligence concepts and terminology</cite></a>.  ISO/IEC. July 2022. Published. URL: <a href="https://www.iso.org/standard/74296.html">https://www.iso.org/standard/74296.html</a>
    </dd><dt id="bib-model-cards">[MODEL-CARDS]</dt><dd>
      <a href="https://arxiv.org/pdf/1810.03993.pdf"><cite>Model Cards for Model Reporting</cite></a>. M. Mitchell; S. Wu; A. Zaldivar; P. Barnes; L. Vasserman; B. Hutchinson; E. Spitzer; I. Deborah Raji; T. Gebru. 14 Juan 2019. URL: <a href="https://arxiv.org/pdf/1810.03993.pdf">https://arxiv.org/pdf/1810.03993.pdf</a>
    </dd><dt id="bib-rfc9309">[RFC9309]</dt><dd>
      <a href="https://www.rfc-editor.org/rfc/rfc9309"><cite>Robots Exclusion Protocol</cite></a>. M. Koster; G. Illyes; H. Zeller; L. Sassman.  IETF. September 2022. Proposed Standard. URL: <a href="https://www.rfc-editor.org/rfc/rfc9309">https://www.rfc-editor.org/rfc/rfc9309</a>
    </dd><dt id="bib-schema-org">[schema-org]</dt><dd>
      <a href="https://schema.org/"><cite>Schema.org</cite></a>. W3C Schema.org Community Group.  W3C. 6.0. URL: <a href="https://schema.org/">https://schema.org/</a>
    </dd><dt id="bib-shape-detection-api">[SHAPE-DETECTION-API]</dt><dd>
      <a href="https://wicg.github.io/shape-detection-api/"><cite>Accelerated Shape Detection in Images</cite></a>.  WICG. cg-draft. URL: <a href="https://wicg.github.io/shape-detection-api/">https://wicg.github.io/shape-detection-api/</a>
    </dd><dt id="bib-speech-api">[SPEECH-API]</dt><dd>
      <a href="https://wicg.github.io/speech-api/"><cite>Web Speech API</cite></a>.  WICG. cg-draft. URL: <a href="https://wicg.github.io/speech-api/">https://wicg.github.io/speech-api/</a>
    </dd><dt id="bib-tdmrep">[TDMRep]</dt><dd>
      <a href="https://www.w3.org/community/reports/tdmrep/CG-FINAL-tdmrep-20240202/"><cite>Final Community Group Report</cite></a>.  Text and Data Mining Reservation Protocol Community Group. February 2024. URL: <a href="https://www.w3.org/community/reports/tdmrep/CG-FINAL-tdmrep-20240202/">https://www.w3.org/community/reports/tdmrep/CG-FINAL-tdmrep-20240202/</a>
    </dd><dt id="bib-trust.txt">[TRUST.TXT]</dt><dd>
      <a href="https://journallist.net/reference-document-for-trust-txt-specifications"><cite>Specification for trust.txt file and underlying system</cite></a>.  JournalList.net. May 2020. URL: <a href="https://journallist.net/reference-document-for-trust-txt-specifications">https://journallist.net/reference-document-for-trust-txt-specifications</a>
    </dd><dt id="bib-unesco-ai">[UNESCO-AI]</dt><dd>
      <a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455"><cite>Recommendation on the Ethics of Artificial Intelligence</cite></a>.  UNESCO. 2021. URL: <a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455">https://unesdoc.unesco.org/ark:/48223/pf0000380455</a>
    </dd><dt id="bib-vc-data-model">[VC-DATA-MODEL]</dt><dd>
      <a href="https://www.w3.org/TR/vc-data-model/"><cite>Verifiable Credentials Data Model v1.1</cite></a>. Manu Sporny; Grant Noble; Dave Longley; Daniel Burnett; Brent Zundel; Kyle Den Hartog.  W3C. 3 March 2022. W3C Recommendation. URL: <a href="https://www.w3.org/TR/vc-data-model/">https://www.w3.org/TR/vc-data-model/</a>
    </dd><dt id="bib-w3c-ml-ws">[W3C-ML-WS]</dt><dd>
      <a href="https://www.w3.org/2020/06/machine-learning-workshop/report.html"><cite>W3C Workshop Report on Web and Machine Learning</cite></a>.  W3C. October 2020. URL: <a href="https://www.w3.org/2020/06/machine-learning-workshop/report.html">https://www.w3.org/2020/06/machine-learning-workshop/report.html</a>
    </dd><dt id="bib-w3c-vision">[w3c-vision]</dt><dd>
      <a href="https://www.w3.org/TR/w3c-vision/"><cite>Vision for W3C</cite></a>. Chris Wilson.  W3C. 3 April 2024. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/w3c-vision/">https://www.w3.org/TR/w3c-vision/</a>
    </dd><dt id="bib-wai-ai">[WAI-AI]</dt><dd>
      <a href="https://www.w3.org/WAI/research/ai2023/"><cite>Artificial Intelligence (AI) and Accessibility Research Symposium 2023</cite></a>.  W3C Web Accessibility Initiative. Jan 2023. URL: <a href="https://www.w3.org/WAI/research/ai2023/">https://www.w3.org/WAI/research/ai2023/</a>
    </dd><dt id="bib-wasm-core-2">[WASM-CORE-2]</dt><dd>
      <a href="https://www.w3.org/TR/wasm-core-2/"><cite>WebAssembly Core Specification</cite></a>. Andreas Rossberg.  W3C. 28 April 2024. W3C Working Draft. URL: <a href="https://www.w3.org/TR/wasm-core-2/">https://www.w3.org/TR/wasm-core-2/</a>
    </dd><dt id="bib-webgpu">[WEBGPU]</dt><dd>
      <a href="https://www.w3.org/TR/webgpu/"><cite>WebGPU</cite></a>. Kai Ninomiya; Brandon Jones; Jim Blandy.  W3C. 8 May 2024. W3C Working Draft. URL: <a href="https://www.w3.org/TR/webgpu/">https://www.w3.org/TR/webgpu/</a>
    </dd><dt id="bib-webmachinelearning-ethics">[webmachinelearning-ethics]</dt><dd>
      <a href="https://www.w3.org/TR/webmachinelearning-ethics/"><cite>Ethical Principles for Web Machine Learning</cite></a>. Anssi Kostiainen.  W3C. 8 January 2024. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/webmachinelearning-ethics/">https://www.w3.org/TR/webmachinelearning-ethics/</a>
    </dd><dt id="bib-webnn">[WEBNN]</dt><dd>
      <a href="https://www.w3.org/TR/webnn/"><cite>Web Neural Network API</cite></a>. Ningxin Hu; Dwayne Robinson.  W3C. 11 May 2024. W3C Candidate Recommendation. URL: <a href="https://www.w3.org/TR/webnn/">https://www.w3.org/TR/webnn/</a>
    </dd></dl>
  </section></section><p role="navigation" id="back-to-top">
    <a href="#title"><abbr title="Back to Top">↑</abbr></a>
  </p><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-artificial-intelligence" aria-label="Links in this document to definition: Artificial Intelligence">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-artificial-intelligence" aria-label="Permalink for definition: Artificial Intelligence. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-artificial-intelligence-1" title="§ 2. Introduction">§ 2. Introduction</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-artificial-intelligence-system" aria-label="Links in this document to definition: AI system">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-artificial-intelligence-system" aria-label="Permalink for definition: AI system. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-artificial-intelligence-system-1" title="§ Abstract">§ Abstract</a> 
    </li><li>
      <a href="#ref-for-dfn-artificial-intelligence-system-2" title="§ Status of This Document">§ Status of This Document</a> 
    </li><li>
      <a href="#ref-for-dfn-artificial-intelligence-system-3" title="§ 1. Executive Summary">§ 1. Executive Summary</a> <a href="#ref-for-dfn-artificial-intelligence-system-4" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-artificial-intelligence-system-5" title="§ 2.1 Terminology">§ 2.1 Terminology</a> 
    </li><li>
      <a href="#ref-for-dfn-artificial-intelligence-system-6" title="§ 3. Intersections between AI systems and the Web">§ 3. Intersections between AI systems and the Web</a> <a href="#ref-for-dfn-artificial-intelligence-system-7" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-artificial-intelligence-system-8" title="§ 4.1.1 Transparency on AI-generated content">§ 4.1.1 Transparency on AI-generated content</a> <a href="#ref-for-dfn-artificial-intelligence-system-9" title="Reference 2">(2)</a> <a href="#ref-for-dfn-artificial-intelligence-system-10" title="Reference 3">(3)</a> 
    </li><li>
      <a href="#ref-for-dfn-artificial-intelligence-system-11" title="§ 4.1.2 Transparency on AI-mediated services">§ 4.1.2 Transparency on AI-mediated services</a> 
    </li><li>
      <a href="#ref-for-dfn-artificial-intelligence-system-12" title="§ 4.4 Sustainability">§ 4.4 Sustainability</a> 
    </li><li>
      <a href="#ref-for-dfn-artificial-intelligence-system-13" title="§ 4.5 Balancing content creators incentives and consumers rights">§ 4.5 Balancing content creators incentives and consumers rights</a> 
    </li><li>
      <a href="#ref-for-dfn-artificial-intelligence-system-14" title="§ 4.5.1 Comparison with search engines">§ 4.5.1 Comparison with search engines</a> <a href="#ref-for-dfn-artificial-intelligence-system-15" title="Reference 2">(2)</a> <a href="#ref-for-dfn-artificial-intelligence-system-16" title="Reference 3">(3)</a> 
    </li><li>
      <a href="#ref-for-dfn-artificial-intelligence-system-17" title="§ 5. Impact of AI systems on interoperability">§ 5. Impact of AI systems on interoperability</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-machine-learning" aria-label="Links in this document to definition: Machine Learning">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-machine-learning" aria-label="Permalink for definition: Machine Learning. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-machine-learning-1" title="§ 2.1 Terminology">§ 2.1 Terminology</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-model" aria-label="Links in this document to definition: Machine Learning model">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-model" aria-label="Permalink for definition: Machine Learning model. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-model-1" title="§ Abstract">§ Abstract</a> 
    </li><li>
      <a href="#ref-for-dfn-model-2" title="§ Status of This Document">§ Status of This Document</a> 
    </li><li>
      <a href="#ref-for-dfn-model-3" title="§ 1. Executive Summary">§ 1. Executive Summary</a> 
    </li><li>
      <a href="#ref-for-dfn-model-4" title="§ 2. Introduction">§ 2. Introduction</a> 
    </li><li>
      <a href="#ref-for-dfn-model-5" title="§ 2.1 Terminology">§ 2.1 Terminology</a> <a href="#ref-for-dfn-model-6" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-model-7" title="§ 3. Intersections between AI systems and the Web">§ 3. Intersections between AI systems and the Web</a> 
    </li><li>
      <a href="#ref-for-dfn-model-8" title="§ 4.1.2 Transparency on AI-mediated services">§ 4.1.2 Transparency on AI-mediated services</a> <a href="#ref-for-dfn-model-9" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-model-10" title="§ 4.3 Safety and security">§ 4.3 Safety and security</a> 
    </li><li>
      <a href="#ref-for-dfn-model-11" title="§ 4.4 Sustainability">§ 4.4 Sustainability</a> <a href="#ref-for-dfn-model-12" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-model-13" title="§ 4.5 Balancing content creators incentives and consumers rights">§ 4.5 Balancing content creators incentives and consumers rights</a> 
    </li><li>
      <a href="#ref-for-dfn-model-14" title="§ 4.5.1 Comparison with search engines">§ 4.5.1 Comparison with search engines</a> <a href="#ref-for-dfn-model-15" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-model-16" title="§ 5. Impact of AI systems on interoperability">§ 5. Impact of AI systems on interoperability</a> <a href="#ref-for-dfn-model-17" title="Reference 2">(2)</a> <a href="#ref-for-dfn-model-18" title="Reference 3">(3)</a> <a href="#ref-for-dfn-model-19" title="Reference 4">(4)</a> <a href="#ref-for-dfn-model-20" title="Reference 5">(5)</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-training" aria-label="Links in this document to definition: training">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-training" aria-label="Permalink for definition: training. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-training-1" title="§ 1. Executive Summary">§ 1. Executive Summary</a> 
    </li><li>
      <a href="#ref-for-dfn-training-2" title="§ 4.1.1 Transparency on AI-generated content">§ 4.1.1 Transparency on AI-generated content</a> 
    </li><li>
      <a href="#ref-for-dfn-training-3" title="§ 4.1.2 Transparency on AI-mediated services">§ 4.1.2 Transparency on AI-mediated services</a> 
    </li><li>
      <a href="#ref-for-dfn-training-4" title="§ 4.2 Right to privacy and data control">§ 4.2 Right to privacy and data control</a> 
    </li><li>
      <a href="#ref-for-dfn-training-5" title="§ 4.4 Sustainability">§ 4.4 Sustainability</a> 
    </li><li>
      <a href="#ref-for-dfn-training-6" title="§ 4.5.1 Comparison with search engines">§ 4.5.1 Comparison with search engines</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-run" aria-label="Links in this document to definition: inference">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-run" aria-label="Permalink for definition: inference. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-run-1" title="§ 3. Intersections between AI systems and the Web">§ 3. Intersections between AI systems and the Web</a> 
    </li><li>
      <a href="#ref-for-dfn-run-2" title="§ 4.2 Right to privacy and data control">§ 4.2 Right to privacy and data control</a> <a href="#ref-for-dfn-run-3" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-run-4" title="§ 4.4 Sustainability">§ 4.4 Sustainability</a> 
    </li><li>
      <a href="#ref-for-dfn-run-5" title="§ 4.5.1 Comparison with search engines">§ 4.5.1 Comparison with search engines</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-bias" aria-label="Links in this document to definition: bias">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-bias" aria-label="Permalink for definition: bias. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-bias-1" title="§ 4.1.2 Transparency on AI-mediated services">§ 4.1.2 Transparency on AI-mediated services</a> <a href="#ref-for-dfn-bias-2" title="Reference 2">(2)</a> <a href="#ref-for-dfn-bias-3" title="Reference 3">(3)</a> <a href="#ref-for-dfn-bias-4" title="Reference 4">(4)</a> <a href="#ref-for-dfn-bias-5" title="Reference 5">(5)</a> 
    </li>
  </ul>
    </div><script id="respec-dfn-panel">(() => {
// @ts-check
if (document.respec) {
  document.respec.ready.then(setupPanel);
} else {
  setupPanel();
}

function setupPanel() {
  const listener = panelListener();
  document.body.addEventListener("keydown", listener);
  document.body.addEventListener("click", listener);
}

function panelListener() {
  /** @type {HTMLElement} */
  let panel = null;
  return event => {
    const { target, type } = event;

    if (!(target instanceof HTMLElement)) return;

    // For keys, we only care about Enter key to activate the panel
    // otherwise it's activated via a click.
    if (type === "keydown" && event.key !== "Enter") return;

    const action = deriveAction(event);

    switch (action) {
      case "show": {
        hidePanel(panel);
        /** @type {HTMLElement} */
        const dfn = target.closest("dfn, .index-term");
        panel = document.getElementById(`dfn-panel-for-${dfn.id}`);
        const coords = deriveCoordinates(event);
        displayPanel(dfn, panel, coords);
        break;
      }
      case "dock": {
        panel.style.left = null;
        panel.style.top = null;
        panel.classList.add("docked");
        break;
      }
      case "hide": {
        hidePanel(panel);
        panel = null;
        break;
      }
    }
  };
}

/**
 * @param {MouseEvent|KeyboardEvent} event
 */
function deriveCoordinates(event) {
  const target = /** @type HTMLElement */ (event.target);

  // We prevent synthetic AT clicks from putting
  // the dialog in a weird place. The AT events sometimes
  // lack coordinates, so they have clientX/Y = 0
  const rect = target.getBoundingClientRect();
  if (
    event instanceof MouseEvent &&
    event.clientX >= rect.left &&
    event.clientY >= rect.top
  ) {
    // The event probably happened inside the bounding rect...
    return { x: event.clientX, y: event.clientY };
  }

  // Offset to the middle of the element
  const x = rect.x + rect.width / 2;
  // Placed at the bottom of the element
  const y = rect.y + rect.height;
  return { x, y };
}

/**
 * @param {Event} event
 */
function deriveAction(event) {
  const target = /** @type {HTMLElement} */ (event.target);
  const hitALink = !!target.closest("a");
  if (target.closest("dfn:not([data-cite]), .index-term")) {
    return hitALink ? "none" : "show";
  }
  if (target.closest(".dfn-panel")) {
    if (hitALink) {
      return target.classList.contains("self-link") ? "hide" : "dock";
    }
    const panel = target.closest(".dfn-panel");
    return panel.classList.contains("docked") ? "hide" : "none";
  }
  if (document.querySelector(".dfn-panel:not([hidden])")) {
    return "hide";
  }
  return "none";
}

/**
 * @param {HTMLElement} dfn
 * @param {HTMLElement} panel
 * @param {{ x: number, y: number }} clickPosition
 */
function displayPanel(dfn, panel, { x, y }) {
  panel.hidden = false;
  // distance (px) between edge of panel and the pointing triangle (caret)
  const MARGIN = 20;

  const dfnRects = dfn.getClientRects();
  // Find the `top` offset when the `dfn` can be spread across multiple lines
  let closestTop = 0;
  let minDiff = Infinity;
  for (const rect of dfnRects) {
    const { top, bottom } = rect;
    const diffFromClickY = Math.abs((top + bottom) / 2 - y);
    if (diffFromClickY < minDiff) {
      minDiff = diffFromClickY;
      closestTop = top;
    }
  }

  const top = window.scrollY + closestTop + dfnRects[0].height;
  const left = x - MARGIN;
  panel.style.left = `${left}px`;
  panel.style.top = `${top}px`;

  // Find if the panel is flowing out of the window
  const panelRect = panel.getBoundingClientRect();
  const SCREEN_WIDTH = Math.min(window.innerWidth, window.screen.width);
  if (panelRect.right > SCREEN_WIDTH) {
    const newLeft = Math.max(MARGIN, x + MARGIN - panelRect.width);
    const newCaretOffset = left - newLeft;
    panel.style.left = `${newLeft}px`;
    /** @type {HTMLElement} */
    const caret = panel.querySelector(".caret");
    caret.style.left = `${newCaretOffset}px`;
  }

  // As it's a dialog, we trap focus.
  // TODO: when <dialog> becomes a implemented, we should really
  // use that.
  trapFocus(panel, dfn);
}

/**
 * @param {HTMLElement} panel
 * @param {HTMLElement} dfn
 * @returns
 */
function trapFocus(panel, dfn) {
  /** @type NodeListOf<HTMLAnchorElement> elements */
  const anchors = panel.querySelectorAll("a[href]");
  // No need to trap focus
  if (!anchors.length) return;

  // Move focus to first anchor element
  const first = anchors.item(0);
  first.focus();

  const trapListener = createTrapListener(anchors, panel, dfn);
  panel.addEventListener("keydown", trapListener);

  // Hiding the panel releases the trap
  const mo = new MutationObserver(records => {
    const [record] = records;
    const target = /** @type HTMLElement */ (record.target);
    if (target.hidden) {
      panel.removeEventListener("keydown", trapListener);
      mo.disconnect();
    }
  });
  mo.observe(panel, { attributes: true, attributeFilter: ["hidden"] });
}

/**
 *
 * @param {NodeListOf<HTMLAnchorElement>} anchors
 * @param {HTMLElement} panel
 * @param {HTMLElement} dfn
 * @returns
 */
function createTrapListener(anchors, panel, dfn) {
  const lastIndex = anchors.length - 1;
  let currentIndex = 0;
  return event => {
    switch (event.key) {
      // Hitting "Tab" traps us in a nice loop around elements.
      case "Tab": {
        event.preventDefault();
        currentIndex += event.shiftKey ? -1 : +1;
        if (currentIndex < 0) {
          currentIndex = lastIndex;
        } else if (currentIndex > lastIndex) {
          currentIndex = 0;
        }
        anchors.item(currentIndex).focus();
        break;
      }

      // Hitting "Enter" on an anchor releases the trap.
      case "Enter":
        hidePanel(panel);
        break;

      // Hitting "Escape" returns focus to dfn.
      case "Escape":
        hidePanel(panel);
        dfn.focus();
        return;
    }
  };
}

/** @param {HTMLElement} panel */
function hidePanel(panel) {
  if (!panel) return;
  panel.hidden = true;
  panel.classList.remove("docked");
}
})()</script><script src="https://www.w3.org/scripts/TR/2021/fixup.js"></script></body></html>